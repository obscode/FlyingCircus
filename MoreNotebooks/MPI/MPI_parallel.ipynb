{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "referenced-kelly",
   "metadata": {},
   "source": [
    "# MPI for python \n",
    "\n",
    "In this notebook, you will learn how to run your python code on many cores using Message Pasing Interface (MPI).  This is the type of \"parallel computing\" you should use to scale your code for running on \"high performance computing\" systems like the HPC facilities at Caltech. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-pixel",
   "metadata": {},
   "source": [
    "## What is parallel programming ?\n",
    "\n",
    "If you run your ordinary python (or any other language) without any parallelization, in practice, it will use only 1 core of your machine while you have many more available. The purpose of parallelzation of a code is to use as many cores as possible to speed up your code. If you parallelize it in an efficient way, the speed-up will be roughly proportional to # of cores used. It is a great benefit when you have access to super-computers which have hundreds of cores available for you. \n",
    "\n",
    "Parallelize your code and get more work done !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-luther",
   "metadata": {},
   "source": [
    "## Quick review of a computer's structure :\n",
    "\n",
    "A stand-alone computer like your current desktop is called a $\\textbf{node}$ which contains few $\\textbf{cores}$ (also clalled CPUs or $\\textbf{processors}$). By default, the memory is shared among all these cores for the purpose of holding data while running your code. e.g. All cores know about the value of a variable which was calculated on any of the cores within the same node.\n",
    "\n",
    "This picture illustrates 2 independent nodes, or computers, being connected via a network. In this example, each node contains 3 cores which share memory among themselves. On the other hand, the two separate nodes do not have shared memory. For example, if a core on the right node needs to know the value of a variable calculated on a core located on the other node, you need to send that data within the network connecting these two nodes. Therefore, communication between cores on different nodes are slower than cores within the same node.\n",
    "\n",
    "![Node-cores](media/node-core.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-strap",
   "metadata": {},
   "source": [
    "## What are the options ?\n",
    "\n",
    "\n",
    "There are 3 options to make your code parallel :\n",
    "\n",
    "1. $\\textbf{Simplest and fastests way}$ : If you want to run the same code on different data chunks, you can simply run your code multiple times and each time feed one chunck of the data to it. Each time you run your code, a single core is hookep up to run your code on it.\n",
    "\n",
    "\n",
    "2. $\\textbf{Shared-Memory parallelization}$: In this approach you let your machine distribute iterative commands like loops among the available cores. If you have 1000 iterations in a loop and 4 cores available, it runs 250 of them on each and at the end it will add up the results from each core to return a single final result. It is called $\\textbf{shared memory}$ parallelization since the memory is physically shared among cores and you do not need to put any effort to communicate between them, i.e. they already know how to combine the results from each core to give you the final result. If you ever hear about $\\textbf{threading}$ or $\\textbf{Open-MP}$, it means this type of parallelization. The down side of this method is that you can never use more than a certain number of cores (number of cores on a single node). Therefore, not the best option for running your code on clusters .\n",
    "\n",
    "$\\textbf{Bad News :}$ The structure of python language is not compatible with shared memory approach, therefore there is not any real implementation of this method for python. There are some work-arounds like [multi processing](https://docs.python.org/3/library/multiprocessing.html). Altough they are easy to implement, it is not very natural to python and therefore very limiting, unlike the next method.\n",
    "\n",
    "\n",
    "3. $\\textbf{MPI}$ : It stands for $\\textbf{Message Passing Interface}$ : In this case, you can run your code on as many as cores as you want even if they are on different nodes. This is the only option when you want to use more than one node. By choosing the number of processes (usually one process per core) which we will call `np`, the machine runs a copy of your code in each process and labels them by an integer called $\\textbf{rank}$ (so number of ranks is the same as number of processes). Also, it establishes a $\\textbf{communicator}$ to transfer in-memory data between different ranks. In MPI, none of the ranks share memory and therefore if you need them to communicate, you have to specify it in your code. \n",
    "\n",
    "Comparing MPI with shared memory or threaded method :\n",
    "\n",
    "![seria-threaded-MPI](media/MPI-threaded-serial.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-winner",
   "metadata": {},
   "source": [
    "## Let's use MPI :\n",
    "\n",
    "1.  First, you need to make sure you have MPI installed. List all the modules available on your system :\n",
    "\n",
    "Mac:\n",
    "\n",
    "```brew list```\n",
    "\n",
    "Linux:\n",
    "\n",
    "```module list```\n",
    "\n",
    "If you find $\\textbf{MPICH}$ on that list, you're good. If not, you should install it :\n",
    "\n",
    "Mac:\n",
    "\n",
    "``` brew install mpich ```\n",
    "\n",
    "Linux (fedora) :\n",
    "\n",
    "``` dnf install  mpich ```\n",
    "\n",
    "Linux (Ubuntu/Debian) :\n",
    "\n",
    "``` sudo apt install mpich ```\n",
    "\n",
    "2. Fortunately a stable MPI package is avaiable for python, [mpi4py](https://mpi4py.readthedocs.io/en/stable/). Install this via conda :\n",
    "\n",
    "``` conda install -c anaconda mpi4py ```\n",
    "\n",
    "Now we are ready to go !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-cache",
   "metadata": {},
   "source": [
    "### Hello World example :\n",
    "\n",
    "The simplest example is asking each rank to print their rank id. Type/copy the code below in a file named `hello_world.py` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bored-stone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I am rank  0  among  1  available ranks!\n",
      "Rank  0  : You can command me privately by specifying my id !\n"
     ]
    }
   ],
   "source": [
    "import mpi4py\n",
    "from mpi4py import MPI\n",
    "\n",
    "# The communicator among ranks\n",
    "comm = MPI.COMM_WORLD\n",
    "# Total number of ranks\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "print('Hi, I am rank ', rank, ' among ', size, ' available ranks!')\n",
    "\n",
    "if rank == 0:\n",
    "    print('Rank ', rank, ' : You can command me privately by specifying my id !')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-environment",
   "metadata": {},
   "source": [
    "\n",
    "Then, you need to run your script on terminal like :\n",
    "\n",
    "` mpirun -np 2 python hellow_world.py`\n",
    "\n",
    "where `-np 2` specifies number of processors you want to use. To see how many cores you have on any Unix machine you can use `htop` package. Type `htop` on terminal and see if you have it installed. If not, you can install it with :\n",
    "\n",
    "mac :\n",
    "\n",
    "` brew install htop`\n",
    "\n",
    "Linux (fedora) :\n",
    "\n",
    "`dnf install htop`\n",
    "\n",
    "Linux (Ubunto/Debian)\n",
    "\n",
    "` sudo apt install htop`\n",
    "\n",
    "Here is a snapshot of what you're expected to see. It shows my desktop has 12 cores and none of them are busy.\n",
    "\n",
    "![htop](media/htop.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-equation",
   "metadata": {},
   "source": [
    "## Comunicating among ranks :\n",
    "\n",
    "\n",
    "MPI has so many buit-in functions to help you communicate among ranks. There are 2 general type of communications :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-joseph",
   "metadata": {},
   "source": [
    "### Ponit-to-point communications :\n",
    "\n",
    "Sometimes you need to send a scalar, numpy arrary or a python object from one rank to another rank. It can be done with functions below :\n",
    "\n",
    "- `send() and recv()` : For transferring scalars and python objects\n",
    "\n",
    "- `Send() and Recv()` : For transfering numpy arrays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-wiring",
   "metadata": {},
   "source": [
    "#### Example : \n",
    "\n",
    "(Credit : [mpi4py documentaion](https://mpi4py.readthedocs.io/en/stable/tutorial.html#point-to-point-communication) )\n",
    "\n",
    "Python objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpi4py\n",
    "from mpi4py import MPI\n",
    "\n",
    "# The communicator among ranks\n",
    "comm = MPI.COMM_WORLD\n",
    "# Total number of ranks\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = {'a': 7, 'b': 3.14}\n",
    "    comm.send(data, dest=1, tag=11)\n",
    "elif rank == 1:\n",
    "    data = comm.recv(source=0, tag=11)\n",
    "    print('rank ', rank, 'data = ', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-expense",
   "metadata": {},
   "source": [
    "NumPy arrays (the fast way!) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpi4py\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "# The communicator among ranks\n",
    "comm = MPI.COMM_WORLD\n",
    "# Total number of ranks\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# passing MPI datatypes explicitly\n",
    "if rank == 0:\n",
    "    data = np.arange(10, dtype='i')\n",
    "    comm.Send([data, MPI.INT], dest=1, tag=77)\n",
    "elif rank == 1:\n",
    "    # You need a buffer for the array\n",
    "    data = np.empty(10, dtype='i')\n",
    "    comm.Recv([data, MPI.INT], source=0, tag=77)\n",
    "    print('Rank ', rank, ' data ', data)\n",
    "\n",
    "# automatic MPI datatype discovery\n",
    "if rank == 0:\n",
    "    data = np.arange(10, dtype=np.float64)\n",
    "    comm.Send(data, dest=1, tag=13)\n",
    "elif rank == 1:\n",
    "    data = np.empty(10, dtype=np.float64)\n",
    "    comm.Recv(data, source=0, tag=13)\n",
    "    print('Rank ', rank, ' data. ', data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-buying",
   "metadata": {},
   "source": [
    " - Tip : All functions for communicating Numpy arrays srtart with capital letters. like `Send()` and `Recv()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-information",
   "metadata": {},
   "source": [
    "### Collective communications :\n",
    "\n",
    "On this type of communication, one rank can send/receive to/from all ranks. So, all ranks are involved. \n",
    "\n",
    "Examples are :\n",
    "\n",
    "` bcast(), Bcast()` : Send a python object or numpy array from one rank to all other ranks :\n",
    "\n",
    "` scatter(), Scatter()` : Scatter a list or numpy array among all ranks \n",
    "\n",
    "`  gather(), Gather() ` : Gather obejcts or numpy arrays in a single list or numpy array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-settlement",
   "metadata": {},
   "source": [
    "#### Examples :\n",
    "\n",
    "(Credit : [mpi4py documentaion](https://mpi4py.readthedocs.io/en/stable/tutorial.html#point-to-point-communication) )\n",
    "\n",
    "Broadcasting for python objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alternative-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank : 0 data = {'key1': [7, 2.72, (2+3j)], 'key2': ('abc', 'xyz')}\n"
     ]
    }
   ],
   "source": [
    "import mpi4py\n",
    "from mpi4py import MPI\n",
    "\n",
    "# The communicator among ranks\n",
    "comm = MPI.COMM_WORLD\n",
    "# Total number of ranks\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = {'key1' : [7, 2.72, 2+3j],\n",
    "            'key2' : ( 'abc', 'xyz')}\n",
    "else:\n",
    "    # You need a buffer\n",
    "    data = None\n",
    "data = comm.bcast(data, root=0)\n",
    "print('Rank :', rank, 'data =', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-doubt",
   "metadata": {},
   "source": [
    "Scattering for python objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comfortable-completion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = [(i+1)**2 for i in range(size)]\n",
    "else:\n",
    "    data = None\n",
    "\n",
    "data = comm.scatter(data, root=0)\n",
    "print('Rank ', rank, 'data = ', data)\n",
    "assert data == (rank+1)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-furniture",
   "metadata": {},
   "source": [
    "Gathering python objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "premium-robin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 data = [1]\n"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "data = (rank+1)**2\n",
    "data = comm.gather(data, root=0)\n",
    "\n",
    "    \n",
    "print('Rank', rank, 'data =', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-listening",
   "metadata": {},
   "source": [
    "Numpy arrays :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "phantom-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = np.arange(10, dtype='i')\n",
    "    # You need to make sure the array's elements are contiguous (no gaps) in memory\n",
    "    data = np.ascontiguousarray(data)\n",
    "\n",
    "else:\n",
    "    # Make a buffer for array\n",
    "    data = np.empty(10, dtype='i')\n",
    "    # You need to make sure the array's elements are contiguous (no gaps) in memory\n",
    "    data = np.ascontiguousarray(data)\n",
    "\n",
    "comm.Bcast(data, root=0)\n",
    "for i in range(10):\n",
    "    assert data[i] == i\n",
    "print('Rank ', rank, ' data ', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "sendbuf = None\n",
    "if rank == 0:\n",
    "    sendbuf = np.empty([size, 10], dtype='i')\n",
    "    sendbuf.T[:,:] = range(size)\n",
    "    # You need to make sure the array's elements are contiguous in memory\n",
    "    sendbuf = np.ascontiguousarray(sendbuf)\n",
    "\n",
    "recvbuf = np.empty(10, dtype='i')\n",
    "# You need to make sure the array's elements are contiguous in memory\n",
    "recvbuf = np.ascontiguousarray(recvbuf)\n",
    "\n",
    "print('Rank ', rank, ' sendbuf ', sendbuf)\n",
    "comm.Scatter(sendbuf, recvbuf, root=0)\n",
    "print('Rank ', rank, ' recvbuf ', recvbuf)\n",
    "assert np.allclose(recvbuf, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "sendbuf = np.zeros(10, dtype='i') + rank\n",
    "# You need to make sure the array's elements are contiguous in memory\n",
    "sendbuf = np.ascontiguousarray(sendbuf)\n",
    "print('Rank ', rank, ' sendbuf ' , sendbuf)\n",
    "recvbuf = None\n",
    "if rank == 0:\n",
    "    recvbuf = np.empty([size, 10], dtype='i')\n",
    "    # You need to make sure the array's elements are contiguous in memory\n",
    "    recvbuf = np.ascontiguousarray(recvbuf)\n",
    "comm.Gather(sendbuf, recvbuf, root=0)\n",
    "\n",
    "print('Rank ', rank, ' recvbuf ' , recvbuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "\n",
    "data = np.arange(10)*0.1*rank\n",
    "# You need to make sure the array's elements are contiguous in memory\n",
    "data = np.ascontiguousarray(data)\n",
    "print('Rank ', rank, ' data before allreduce ', data)\n",
    "comm.Allreduce(MPI.IN_PLACE, data, op=MPI.SUM)\n",
    "print('Rank ', rank, ' data after  allreduce ', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-pocket",
   "metadata": {},
   "source": [
    "- There are many other built-in functions that are optimized for minimal computation and memory usage. [This website](https://pages.tacc.utexas.edu/~eijkhout/pcse/html/index.html) is a great resource for learning more about MPI and all other useful communications. These functions behave similarly in python, C and Fortran, but the syntax is slightly different in each. This website has examples for all 3  languages on each topic. \n",
    "\n",
    "- I also recommend you to look at [mpi4py documentation](https://mpi4py.readthedocs.io/en/stable/tutorial.html#point-to-point-communication) and any other resource you might find on google."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
